{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ee11778-03d0-466c-aa00-e02aa3ca6742",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Install libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "529a0011-5e95-4f44-b6eb-830f6bebf12b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in /Users/kenny/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (3.7.4)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /Users/kenny/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /Users/kenny/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/kenny/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from spacy) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/kenny/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from spacy) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/kenny/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from spacy) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /Users/kenny/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from spacy) (8.2.3)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /Users/kenny/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from spacy) (1.1.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /Users/kenny/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from spacy) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /Users/kenny/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /Users/kenny/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from spacy) (0.3.4)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /Users/kenny/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from spacy) (0.9.4)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /Users/kenny/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from spacy) (6.4.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/kenny/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from spacy) (4.66.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/kenny/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from spacy) (2.31.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /Users/kenny/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from spacy) (2.7.1)\n",
      "Requirement already satisfied: jinja2 in /Users/kenny/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from spacy) (3.1.3)\n",
      "Requirement already satisfied: setuptools in /Users/kenny/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from spacy) (69.1.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/kenny/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from spacy) (23.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /Users/kenny/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from spacy) (3.4.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /Users/kenny/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from spacy) (1.26.4)\n",
      "Requirement already satisfied: language-data>=1.2 in /Users/kenny/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/kenny/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.2 in /Users/kenny/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.18.2)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /Users/kenny/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.10.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/kenny/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/kenny/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/kenny/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/kenny/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.2.2)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /Users/kenny/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /Users/kenny/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /Users/kenny/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from typer<0.10.0,>=0.3.0->spacy) (8.1.7)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /Users/kenny/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from weasel<0.4.0,>=0.1.0->spacy) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/kenny/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from jinja2->spacy) (2.1.5)\n",
      "Requirement already satisfied: marisa-trie>=0.7.7 in /Users/kenny/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.1.0)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "928d3710-c497-4c91-8689-6f042f84cd41",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.7.1\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /Users/kenny/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from en-core-web-sm==3.7.1) (3.7.4)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /Users/kenny/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /Users/kenny/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/kenny/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/kenny/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/kenny/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /Users/kenny/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.3)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /Users/kenny/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /Users/kenny/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /Users/kenny/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /Users/kenny/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.3.4)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /Users/kenny/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.9.4)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /Users/kenny/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (6.4.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/kenny/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.66.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/kenny/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.31.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /Users/kenny/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.7.1)\n",
      "Requirement already satisfied: jinja2 in /Users/kenny/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.3)\n",
      "Requirement already satisfied: setuptools in /Users/kenny/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (69.1.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/kenny/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (23.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /Users/kenny/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.4.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /Users/kenny/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.26.4)\n",
      "Requirement already satisfied: language-data>=1.2 in /Users/kenny/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/kenny/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.2 in /Users/kenny/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.18.2)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /Users/kenny/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.10.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/kenny/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/kenny/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/kenny/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/kenny/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2024.2.2)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /Users/kenny/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /Users/kenny/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /Users/kenny/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.1.7)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /Users/kenny/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/kenny/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.1.5)\n",
      "Requirement already satisfied: marisa-trie>=0.7.7 in /Users/kenny/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.0)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!{sys.executable} -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c586e51e-060f-4927-bbec-9fb6b8cf7c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries\n",
    "import spacy\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f28e1504-45a1-41fe-afb6-1d8339d4df93",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load spacy's default language\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68c67cf-3eaf-46af-8f4a-8d1ce7a6ecea",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Getting started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ec37d148-5824-4abe-82e8-84810847f13a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'spacy.tokens.doc.Doc'>\n",
      "['This', 'tutorial', 'is', 'about', 'Natural', 'Language', 'Processing', 'in', 'spaCy', '.']\n"
     ]
    }
   ],
   "source": [
    "# Construct a Doc object, which a sequence of token objects, representing a lexical token\n",
    "# Each token has information about a particular piece of text\n",
    "# Create a Doc object, which allows us to access information about the processed text\n",
    "# The doc is separated into tokens, which breaks down the sentence into its individual words\n",
    "introduction_doc = nlp(\"This tutorial is about Natural Language Processing in spaCy. \")\n",
    "print(type(introduction_doc))\n",
    "# Create a series of Token objects\n",
    "print([token.text for token in introduction_doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "904a5ff6-0d41-46f5-b1d5-8ec92d78ebb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/kenny/Developer/jupyter/natural_language_processing/introduction.txt\n",
      "['This', 'tutorial', 'is', 'about', 'Natural', 'Language', 'Processing', 'in', 'spaCy', '.']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "notebook_path = os.path.abspath(\"natural_language_processing/introduction.txt\")\n",
    "print(notebook_path)\n",
    "\n",
    "introduction_doc = nlp(pathlib.Path(notebook_path).read_text(encoding=\"utf-8\"))\n",
    "print ([token.text for token in introduction_doc])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "795dd68b-3707-4793-96e0-dcef4d27d9af",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Sentence detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "102aafeb-2829-4013-9c86-4b323854d36d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gus Proto is a Python developer currently working for a London-based Fintech company....\n",
      "He is interested in learning Natural Language Processing....\n"
     ]
    }
   ],
   "source": [
    "# Locate where sentences start and end in a given text (simply find where the period is)\n",
    "about_text = (\n",
    "     \"Gus Proto is a Python developer currently working for a London-based Fintech company. He is interested in learning Natural Language Processing.\"\n",
    ")\n",
    "\n",
    "# Create the nlp object\n",
    "about_doc = nlp(about_text)\n",
    "# .sents attribute \n",
    "sentences = list(about_doc.sents)\n",
    "len(sentences)\n",
    "\n",
    "for sentence in sentences:\n",
    "    print(f\"{sentence[::]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c1bcff5-b641-43cd-b26d-a982c13d4e8e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Creating custom sentence pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c629e791-3ab4-4a45-a8ba-c8e85cfb0aa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gus, can you, ...\n",
      "never mind, I forgot what I was saying.\n",
      "So, do you think we should ...\n"
     ]
    }
   ],
   "source": [
    "ellipsis_text = (\"Gus, can you, ... never mind, I forgot what I was saying. So, do you think we should ...\")\n",
    "\n",
    "from spacy.language import Language\n",
    "@Language.component(\"set_custom_boundaries\")\n",
    "def set_custom_boundaries(doc):\n",
    "    for token in doc [:-1]:\n",
    "        if token.text == \"...\":\n",
    "            doc[token.i+1].is_sent_start = True\n",
    "    return doc\n",
    "    \n",
    "#Create another nlp class\n",
    "custom_nlp = spacy.load(\"en_core_web_sm\")\n",
    "# Adding a custom pipeline\n",
    "custom_nlp.add_pipe(\"set_custom_boundaries\", before=\"parser\")\n",
    "# Create a doc object and pass in the text\n",
    "custom_ellipsis_doc = custom_nlp(ellipsis_text)\n",
    "# Iterating over sentences, the Doc objects' sentences occur at \"...\" and \".\"\n",
    "custom_ellipsis_sentences = list(custom_ellipsis_doc.sents)\n",
    "for sentence in custom_ellipsis_sentences:\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c29ed9dc-8325-4276-81f0-f424632e5fb2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ff3c3418-1e01-43c5-886b-d6236552e2da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gus 0\n",
      "Proto 4\n",
      "is 10\n",
      "a 13\n",
      "Python 15\n",
      "developer 22\n",
      "currently 32\n",
      "working 42\n",
      "for 50\n",
      "a 54\n",
      "London 56\n",
      "- 62\n",
      "based 63\n",
      "Fintech 69\n",
      "company 77\n",
      ". 84\n",
      "He 86\n",
      "is 89\n",
      "interested 92\n",
      "in 103\n",
      "learning 106\n",
      "Natural 115\n",
      "Language 123\n",
      "Processing 132\n",
      ". 142\n"
     ]
    }
   ],
   "source": [
    "# Tokenization breaks down a text into basic units or tokens\n",
    "# Tokens have the word they store, and the index in the string, as an attribute\n",
    "about_text = (\n",
    "     \"Gus Proto is a Python developer currently working for a London-based Fintech company. He is interested in learning Natural Language Processing.\"\n",
    ")\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "about_doc = nlp(about_text)\n",
    "\n",
    "for token in about_doc:\n",
    "    print (token, token.idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e19e4152-c12d-4a28-ac83-33b48225e7cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text with Whitespace  Is Alphanumeric?Is Punctuation?   Is Stop Word?\n",
      "Gus                   True           False             False\n",
      "Proto                 True           False             False\n",
      "is                    True           False             True\n",
      "a                     True           False             True\n",
      "Python                True           False             False\n",
      "developer             True           False             False\n",
      "currently             True           False             False\n",
      "working               True           False             False\n",
      "for                   True           False             True\n",
      "a                     True           False             True\n",
      "London                True           False             False\n",
      "-                     False          True              False\n",
      "based                 True           False             False\n",
      "Fintech               True           False             False\n",
      "company               True           False             False\n",
      ".                     False          True              False\n",
      "He                    True           False             True\n",
      "is                    True           False             True\n",
      "interested            True           False             False\n",
      "in                    True           False             True\n",
      "learning              True           False             False\n",
      "Natural               True           False             False\n",
      "Language              True           False             False\n",
      "Processing            True           False             False\n",
      ".                     False          True              False\n"
     ]
    }
   ],
   "source": [
    "# Spacy also gives other types of information about a piece of text\n",
    "\n",
    "print(\n",
    "    f\"{\"Text with Whitespace\":22}\"\n",
    "    f\"{\"Is Alphanumeric?\":15}\"\n",
    "    f\"{\"Is Punctuation?\":18}\"\n",
    "    f\"{\"Is Stop Word?\"}\"\n",
    ")\n",
    "for token in about_doc:\n",
    "    print(\n",
    "        # Trailing space or not\n",
    "        f\"{str(token.text_with_ws):22}\"\n",
    "        # Alphabetic characters or not\n",
    "        f\"{str(token.is_alpha):15}\"\n",
    "        # Is a punctuation symbol or not\n",
    "        f\"{str(token.is_punct):18}\"\n",
    "        # Is a stop word or not\n",
    "        f\"{str(token.is_stop)}\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65dd590-a4d0-4ff6-9261-d53dd356435e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Custom tokenization process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "cea5ce35-9ab4-43eb-8cd3-c5cff505a066",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['for', 'a', 'London@based', 'Fintech', 'company', '.', 'He']\n",
      "['for', 'a', 'London', '@', 'based', 'Fintech', 'company']\n"
     ]
    }
   ],
   "source": [
    "custom_about_text = (\n",
    "     \"Gus Proto is a Python developer currently working for a London@based Fintech company. He is interested in learning Natural Language Processing.\"\n",
    ")\n",
    "# London@based is read as one token\n",
    "print([token.text for token in nlp(custom_about_text)[8:15]])\n",
    "\n",
    "import re\n",
    "from spacy.tokenizer import Tokenizer\n",
    "\n",
    "custom_nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Generate the custom regex objects for the Tokenizer\n",
    "prefix_re = spacy.util.compile_prefix_regex(\n",
    "    custom_nlp.Defaults.prefixes\n",
    ")\n",
    "suffix_re = spacy.util.compile_suffix_regex(\n",
    "    custom_nlp.Defaults.suffixes\n",
    ")\n",
    "\n",
    "# Add a custom infix with new regex patterns\n",
    "custom_infixes = [r\"@\"]\n",
    "\n",
    "# Join the custom infixes\n",
    "infix_re = spacy.util.compile_infix_regex(\n",
    "    list(custom_nlp.Defaults.infixes) + custom_infixes\n",
    ")\n",
    "\n",
    "# print(custom_nlp.Defaults.infixes)\n",
    "\n",
    "# Create a custom nlp tokenizer\n",
    "custom_nlp.tokenizer = Tokenizer(\n",
    "    # Handles contractions and emoticons\n",
    "    nlp.vocab,\n",
    "    # Handles preceding punctuation (eg. opening parenthesis)\n",
    "    prefix_search=prefix_re.search,\n",
    "    # Handles ending punctuation  (eg. closing parenthesis)\n",
    "    suffix_search=suffix_re.search,\n",
    "    # Handles non-whitespace separators such as hyphens\n",
    "    infix_finditer=infix_re.finditer,\n",
    "    # Handles strings that should not split, including links and numbers\n",
    "    token_match=None,\n",
    ")\n",
    "\n",
    "custom_tokenizer_about_doc = custom_nlp(custom_about_text)\n",
    "\n",
    "print([token.text for token in custom_tokenizer_about_doc[8:15]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "24788e88-3c27-4bf0-b70c-84fd79fc017b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Gus, Proto, Python, developer, currently, working, London@based, Fintech, company, ., interested, learning, Natural, Language, Processing, .]\n"
     ]
    }
   ],
   "source": [
    "# Stop words\n",
    "# Defined as common words in a language such as \"the, but, they, etc\"\n",
    "# Stop words are generally removed from NLP because they aren't significant\n",
    "spacy_stopwords = spacy.lang.en.stop_words.STOP_WORDS\n",
    "len(spacy_stopwords)\n",
    "# print(spacy_stopwords)\n",
    "\n",
    "custom_about_text = (\n",
    "     \"Gus Proto is a Python developer currently working for a London@based Fintech company. He is interested in learning Natural Language Processing.\"\n",
    ")\n",
    "\n",
    "about_doc = nlp(custom_about_text)\n",
    "print([token for token in about_doc if not token.is_stop])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ba8206-2ec2-4d31-a251-8bb03aa2281f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "fed33dc8-4086-4059-b171-e494b6e1972a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  is : be\n",
      "                  He : he\n",
      "               keeps : keep\n",
      "          organizing : organize\n",
      "             meetups : meetup\n",
      "               talks : talk\n"
     ]
    }
   ],
   "source": [
    "# Reducing inflected forms of a word while still enduring the reduced form belongs to the language\n",
    "# The reduced word is a root word that is called a lemma\n",
    "# eg. organize, organzed, organizing are all forms of the word organize, and organize is the lemma\n",
    "# Lemmatization helps you reduce the inflected forms of a word so they can be analyzed as a single item\n",
    "# Lemmatization helps you avoid duplicate words\n",
    "conference_help_text = (\n",
    "    \"Gus is helping organize a developer conference on Applications of Natural Language Processing. He keeps organizing local Python meetups and several internal talks at his workplace.\"\n",
    ")\n",
    "\n",
    "conference_help_doc = nlp(conference_help_text)\n",
    "\n",
    "for token in conference_help_doc:\n",
    "    if str(token) != str(token.lemma_):\n",
    "        print(f\"{str(token):>20} : {str(token.lemma_)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1823160d-2bef-4118-a142-1429bae9f9d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Gus', 3), ('Natural', 3), ('Language', 3), ('Processing', 3), ('Python', 2), ('developer', 2), ('London', 2), ('Fintech', 2), ('talk', 2), ('Proto', 1)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('is', 8),\n",
       " ('a', 5),\n",
       " ('Gus', 3),\n",
       " ('in', 3),\n",
       " ('Natural', 3),\n",
       " ('Language', 3),\n",
       " ('Processing', 3),\n",
       " ('Python', 2)]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Word frequency analysis example\n",
    "from collections import Counter\n",
    "complete_text = (\"Gus Proto is a Python developer currently working for a London-based Fintech company. He is interested in learning Natural Language Processing. There is a developer conference happening on 21 July 2019 in London. It is titled 'Applications of Natural Language Processing'. There is a helpline number Ωavailable at +44-1234567891. Gus is helping organize it. He keeps organizing local Python meetups and several internal talks at his workplace. Gus is also presenting a talk. The talk will introduce the reader about the use cases of Natural Language Processing in Fintech. Apart from his work, he is very passionate about music.\")\n",
    "\n",
    "complete_doc = nlp(complete_text)\n",
    "\n",
    "# Remove all stop words\n",
    "words = [\n",
    "    token.text\n",
    "    for token in complete_doc\n",
    "    if not token.is_stop and not token.is_punct\n",
    "]\n",
    "\n",
    "print(Counter(words).most_common(10))\n",
    "\n",
    "# If we did not remove stop words:\n",
    "\n",
    "Counter(\n",
    "    [token.text for token in complete_doc if not token.is_punct]\n",
    ").most_common(8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c00be0a1-3dc9-42aa-a7f9-02ad482c5cf4",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Speech tagging\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "24ad4a23-1606-4fee-9f58-78ae8129dad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        TOKEN: Gus\n",
      "        =====\n",
      "        TAG: NNP        POS: PROPN\n",
      "        EXPLANATION: noun, proper singular\n",
      "\n",
      "        TOKEN: Proto\n",
      "        =====\n",
      "        TAG: NNP        POS: PROPN\n",
      "        EXPLANATION: noun, proper singular\n",
      "\n",
      "        TOKEN: is\n",
      "        =====\n",
      "        TAG: VBZ        POS: AUX\n",
      "        EXPLANATION: verb, 3rd person singular present\n",
      "\n",
      "        TOKEN: a\n",
      "        =====\n",
      "        TAG: DT         POS: DET\n",
      "        EXPLANATION: determiner\n",
      "\n",
      "        TOKEN: Python\n",
      "        =====\n",
      "        TAG: NNP        POS: PROPN\n",
      "        EXPLANATION: noun, proper singular\n",
      "\n",
      "        TOKEN: developer\n",
      "        =====\n",
      "        TAG: NN         POS: NOUN\n",
      "        EXPLANATION: noun, singular or mass\n",
      "\n",
      "        TOKEN: currently\n",
      "        =====\n",
      "        TAG: RB         POS: ADV\n",
      "        EXPLANATION: adverb\n",
      "\n",
      "        TOKEN: working\n",
      "        =====\n",
      "        TAG: VBG        POS: VERB\n",
      "        EXPLANATION: verb, gerund or present participle\n",
      "\n",
      "        TOKEN: for\n",
      "        =====\n",
      "        TAG: IN         POS: ADP\n",
      "        EXPLANATION: conjunction, subordinating or preposition\n",
      "\n",
      "        TOKEN: a\n",
      "        =====\n",
      "        TAG: DT         POS: DET\n",
      "        EXPLANATION: determiner\n",
      "\n",
      "        TOKEN: London\n",
      "        =====\n",
      "        TAG: NNP        POS: PROPN\n",
      "        EXPLANATION: noun, proper singular\n",
      "\n",
      "        TOKEN: -\n",
      "        =====\n",
      "        TAG: HYPH       POS: PUNCT\n",
      "        EXPLANATION: punctuation mark, hyphen\n",
      "\n",
      "        TOKEN: based\n",
      "        =====\n",
      "        TAG: VBN        POS: VERB\n",
      "        EXPLANATION: verb, past participle\n",
      "\n",
      "        TOKEN: Fintech\n",
      "        =====\n",
      "        TAG: NNP        POS: PROPN\n",
      "        EXPLANATION: noun, proper singular\n",
      "\n",
      "        TOKEN: company\n",
      "        =====\n",
      "        TAG: NN         POS: NOUN\n",
      "        EXPLANATION: noun, singular or mass\n",
      "\n",
      "        TOKEN: .\n",
      "        =====\n",
      "        TAG: .          POS: PUNCT\n",
      "        EXPLANATION: punctuation mark, sentence closer\n",
      "\n",
      "        TOKEN: He\n",
      "        =====\n",
      "        TAG: PRP        POS: PRON\n",
      "        EXPLANATION: pronoun, personal\n",
      "\n",
      "        TOKEN: is\n",
      "        =====\n",
      "        TAG: VBZ        POS: AUX\n",
      "        EXPLANATION: verb, 3rd person singular present\n",
      "\n",
      "        TOKEN: interested\n",
      "        =====\n",
      "        TAG: JJ         POS: ADJ\n",
      "        EXPLANATION: adjective (English), other noun-modifier (Chinese)\n",
      "\n",
      "        TOKEN: in\n",
      "        =====\n",
      "        TAG: IN         POS: ADP\n",
      "        EXPLANATION: conjunction, subordinating or preposition\n",
      "\n",
      "        TOKEN: learning\n",
      "        =====\n",
      "        TAG: VBG        POS: VERB\n",
      "        EXPLANATION: verb, gerund or present participle\n",
      "\n",
      "        TOKEN: Natural\n",
      "        =====\n",
      "        TAG: NNP        POS: PROPN\n",
      "        EXPLANATION: noun, proper singular\n",
      "\n",
      "        TOKEN: Language\n",
      "        =====\n",
      "        TAG: NNP        POS: PROPN\n",
      "        EXPLANATION: noun, proper singular\n",
      "\n",
      "        TOKEN: Processing\n",
      "        =====\n",
      "        TAG: NNP        POS: PROPN\n",
      "        EXPLANATION: noun, proper singular\n",
      "\n",
      "        TOKEN: .\n",
      "        =====\n",
      "        TAG: .          POS: PUNCT\n",
      "        EXPLANATION: punctuation mark, sentence closer\n",
      "[developer, company]\n",
      "[interested]\n"
     ]
    }
   ],
   "source": [
    "# Speech tagging explains how a word is used in a particular sentence\n",
    "# Noun, pronoun, adjective, verb, adverb, preposition, conjunction, injerjunction\n",
    "# Part of speech tagging assigns a POS tag to each token depending on its usage in a sentence\n",
    "# Assigns a noun or verb to each word\n",
    "# Can be used to gauge sentiment by analyzing which adjectives are commonly used alongside nouns\n",
    "\n",
    "about_text = (\n",
    "     \"Gus Proto is a Python developer currently working for a London-based Fintech company. He is interested in learning Natural Language Processing.\"\n",
    ")\n",
    "\n",
    "about_doc = nlp(about_text)\n",
    "for token in about_doc:\n",
    "    print(\n",
    "        f\"\"\"\n",
    "        TOKEN: {str(token)}\n",
    "        =====\n",
    "        TAG: {str(token.tag_):10} POS: {token.pos_}\n",
    "        EXPLANATION: {spacy.explain(token.tag_)}\"\"\"\n",
    "        )\n",
    "        #.tag displays the fine-grained tag, and .pos displays the coarse-grained tag\n",
    "        # These classify what the word's purpose is in a sentence in speech or writing\n",
    "\n",
    "\n",
    "\n",
    "nouns = []\n",
    "adjectives = []\n",
    "for token in about_doc:\n",
    "    if token.pos_ == \"NOUN\":\n",
    "        nouns.append(token)\n",
    "    if token.pos_ == \"ADJ\":\n",
    "        adjectives.append(token)\n",
    "\n",
    "\n",
    "print(nouns)\n",
    "\n",
    "\n",
    "print(adjectives)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be98591e-8cd4-4fc6-890f-0f949f98c208",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Visualization using displaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "253bf521-3134-48b4-b7b6-7516a4fb8994",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"cba66b2079e945d5b0201606e05c2950-0\" class=\"displacy\" width=\"1450\" height=\"312.0\" direction=\"ltr\" style=\"max-width: none; height: 312.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">He</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">is</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">AUX</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">interested</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">in</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">learning</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">Natural</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">Language</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">Processing.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-cba66b2079e945d5b0201606e05c2950-0-0\" stroke-width=\"2px\" d=\"M70,177.0 C70,89.5 220.0,89.5 220.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-cba66b2079e945d5b0201606e05c2950-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,179.0 L62,167.0 78,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-cba66b2079e945d5b0201606e05c2950-0-1\" stroke-width=\"2px\" d=\"M245,177.0 C245,89.5 395.0,89.5 395.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-cba66b2079e945d5b0201606e05c2950-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">acomp</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M395.0,179.0 L403.0,167.0 387.0,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-cba66b2079e945d5b0201606e05c2950-0-2\" stroke-width=\"2px\" d=\"M420,177.0 C420,89.5 570.0,89.5 570.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-cba66b2079e945d5b0201606e05c2950-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M570.0,179.0 L578.0,167.0 562.0,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-cba66b2079e945d5b0201606e05c2950-0-3\" stroke-width=\"2px\" d=\"M595,177.0 C595,89.5 745.0,89.5 745.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-cba66b2079e945d5b0201606e05c2950-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pcomp</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M745.0,179.0 L753.0,167.0 737.0,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-cba66b2079e945d5b0201606e05c2950-0-4\" stroke-width=\"2px\" d=\"M945,177.0 C945,89.5 1095.0,89.5 1095.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-cba66b2079e945d5b0201606e05c2950-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M945,179.0 L937,167.0 953,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-cba66b2079e945d5b0201606e05c2950-0-5\" stroke-width=\"2px\" d=\"M1120,177.0 C1120,89.5 1270.0,89.5 1270.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-cba66b2079e945d5b0201606e05c2950-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1120,179.0 L1112,167.0 1128,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-cba66b2079e945d5b0201606e05c2950-0-6\" stroke-width=\"2px\" d=\"M770,177.0 C770,2.0 1275.0,2.0 1275.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-cba66b2079e945d5b0201606e05c2950-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1275.0,179.0 L1283.0,167.0 1267.0,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Used to visualize dependency parse or named entities in a browser\n",
    "from spacy import displacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "about_interest_text = ( \"He is interested in learning Natural Language Processing.\")\n",
    "\n",
    "about_interest_doc = nlp(about_interest_text)\n",
    "\n",
    "displacy.render(about_interest_doc, style=\"dep\", jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607be9b8-704a-4f0d-bca5-8be88b1f0a62",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Cleaning data example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "b20a378b-d36a-493a-bb61-b44e035882f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gus',\n",
       " 'proto',\n",
       " 'python',\n",
       " 'developer',\n",
       " 'currently',\n",
       " 'work',\n",
       " 'london',\n",
       " 'base',\n",
       " 'fintech',\n",
       " 'company',\n",
       " 'interested',\n",
       " 'learn',\n",
       " 'natural',\n",
       " 'language',\n",
       " 'processing',\n",
       " 'developer',\n",
       " 'conference',\n",
       " 'happen',\n",
       " '21',\n",
       " 'july2019',\n",
       " 'london',\n",
       " 'title',\n",
       " 'application',\n",
       " 'naturallanguage',\n",
       " 'processing',\n",
       " 'helpline',\n",
       " 'number',\n",
       " 'available',\n",
       " '+44',\n",
       " '1234567891',\n",
       " 'gus',\n",
       " 'helping',\n",
       " 'organize',\n",
       " 'keep',\n",
       " 'organize',\n",
       " 'local',\n",
       " 'python',\n",
       " 'meetup',\n",
       " 'internal',\n",
       " 'talk',\n",
       " 'workplace',\n",
       " 'gus',\n",
       " 'presentinga',\n",
       " 'talk',\n",
       " 'talk',\n",
       " 'introduce',\n",
       " 'reader',\n",
       " \"use'cases\",\n",
       " 'natural',\n",
       " 'language',\n",
       " 'processing',\n",
       " \"fintech'\",\n",
       " 'apart',\n",
       " 'work',\n",
       " 'passionate',\n",
       " 'music',\n",
       " 'gus',\n",
       " 'learn',\n",
       " 'play',\n",
       " 'piano',\n",
       " 'enrol',\n",
       " 'weekend',\n",
       " 'batch',\n",
       " 'great',\n",
       " 'piano',\n",
       " 'academy',\n",
       " 'great',\n",
       " 'piano',\n",
       " 'academy',\n",
       " 'situate',\n",
       " 'mayfair',\n",
       " 'city',\n",
       " 'london',\n",
       " 'world',\n",
       " 'class',\n",
       " 'piano',\n",
       " 'instructor']"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lowercase the text\n",
    "# Lemmatize each token\n",
    "# Remove punctuation symbols\n",
    "# Remove stop words\n",
    "\n",
    "complete_text = (\"Gus Proto is a Python developer currently working for a London-based Fintech company. He is interested in learning Natural Language Processing.There is a developer conference happening on 21 July2019 in London. It is titled 'Applications of NaturalLanguage Processing'. There is a helpline number available at +44-1234567891. Gus is helping organize it. He keeps organizing local Python meetups and several internal talks at his workplace. Gus is also presentinga talk. The talk will introduce the reader about 'Use'cases of Natural Language Processing in Fintech'.Apart from his work, he is very passionate about music.Gus is learning to play the Piano. He has enrolled himself in the weekend batch of Great Piano Academy. Great Piano Academy is situated in Mayfair or the City of London and has world-class piano instructors.\")\n",
    "\n",
    "complete_doc = nlp(complete_text)\n",
    "\n",
    "# Define functions\n",
    "def is_token_allowed(token):\n",
    "    # Filter tokens that are NOT punctuation or stop words\n",
    "    return bool(token and str(token).strip() and not token.is_stop and not token.is_punct)\n",
    "\n",
    "def preprocess_token(token):\n",
    "    # Lowercase, and remove whitespace\n",
    "    return token.lemma_.strip().lower()\n",
    "\n",
    "complete_filtered_tokens = [preprocess_token(token) for token in complete_doc if is_token_allowed(token)]\n",
    "\n",
    "complete_filtered_tokens\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d93217be-f0a1-4896-8ab9-db058d62651d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Rule based matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "9e16aaae-4037-4850-8141-0cf47d3f89f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Kenny Guo'"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One of the steps to extract information from unstructured text\n",
    "# Identify and extract tokens based on patterns such as lowercase and grammatical features\n",
    "# Match  a label according to lexical patterns and grammical features\n",
    "\n",
    "# First and last names are always proper nouns\n",
    "# Extracting names\n",
    "\n",
    "complete_text = (\"Bo is a Python developer at Kenny Guo currently working for a London-based Fintech company. He is interested in learning Natural Language Processing.There is a developer conference happening on 21 July2019 in London. It is titled 'Applications of NaturalLanguage Processing'. There is a helpline number available at +44-1234567891. Gus is helping organize it. He keeps organizing local Python meetups and several internal talks at his workplace. Gus is also presentinga talk. The talk will introduce the reader about 'Use'cases of Natural Language Processing in Fintech'.Apart from his work, he is very passionate about music.Gus is learning to play the Piano. He has enrolled himself in the weekend batch of Great Piano Academy. Great Piano Academy is situated in Mayfair or the City of London and has world-class piano instructors.\")\n",
    "\n",
    "complete_doc = nlp(complete_text)\n",
    "\n",
    "from spacy.matcher import Matcher\n",
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "def dump(obj):\n",
    "  for attr in dir(obj):\n",
    "    print(\"obj.%s = %r\" % (attr, getattr(obj, attr)))\n",
    "\n",
    "# dump(nlp.vocab)\n",
    "\n",
    "# pattern is a list of objects, of the combination of tokens to be matched\n",
    "# pattern consists of two objects in which POS tags for both tokens are PROPN (proper nouns)\n",
    "# The pattern is added to Matcher with the .add method\n",
    "def extract_full_name(nlp_doc):\n",
    "    pattern = [{\"POS\": \"PROPN\"}, {\"POS\": \"PROPN\"}]\n",
    "    matcher.add(\"FULL_NAME\", [pattern])\n",
    "    matches = matcher(nlp_doc)\n",
    "    for _, start, end in matches:\n",
    "        span = nlp_doc[start:end]\n",
    "        yield span.text\n",
    "\n",
    "\n",
    "next(extract_full_name(complete_doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "d80bd9d3-d836-441d-b4a1-1ec0c44b3a44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(2475408655227838177, 20, 22), (10788718092470551940, 30, 36)]\n",
      "Language Processing\n",
      "(123) 456-7891\n"
     ]
    }
   ],
   "source": [
    "conference_org_text = (\"There is a developer conference happening on 21 July 2019 in London. It is titled the applications of natural language processing. There is a helpline number available at (123) 456-7891 for you\")\n",
    "\n",
    "\n",
    "def extract_phone_number(nlp_doc):\n",
    "    pattern = [\n",
    "        # ORTH matches the exact text of the token\n",
    "        # SHAPE transforms the token to show orthographic features\n",
    "        # OP defines operators - using ? means that a pattern is optional\n",
    "        {\"ORTH\": \"(\"}, # opening bracket\n",
    "        {\"SHAPE\": \"ddd\"}, # 3 digits\n",
    "        {\"ORTH\": \")\"}, # closing bracket\n",
    "        {\"SHAPE\": \"ddd\"}, #3 digits\n",
    "        {\"ORTH\": \"-\", \"OP\": \"?\"}, # can have a hyphen\n",
    "        {\"SHAPE\": \"dddd\"}, # 4 digits\n",
    "    ]\n",
    "    matcher.add(\"PHONE_NUMBER\", [pattern])\n",
    "    matches = matcher(nlp_doc)\n",
    "    print(matches)\n",
    "    for match_id, start, end in matches:\n",
    "        span = nlp_doc[start:end]\n",
    "        print(span)\n",
    "\n",
    "\n",
    "conference_org_doc = nlp(conference_org_text)\n",
    "extract_phone_number(conference_org_doc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82eff5f6-0b4f-4e71-857c-dbe170488702",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Depedency parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "4134d9c7-b211-402f-b6f5-e45f37a601c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TOKEN: Gus\n",
      "=====\n",
      "token.tag_ = 'NNP'\n",
      "token.head.text = 'learning'\n",
      "token.dep_ = 'nsubj'\n",
      "\n",
      "TOKEN: is\n",
      "=====\n",
      "token.tag_ = 'VBZ'\n",
      "token.head.text = 'learning'\n",
      "token.dep_ = 'aux'\n",
      "\n",
      "TOKEN: learning\n",
      "=====\n",
      "token.tag_ = 'VBG'\n",
      "token.head.text = 'learning'\n",
      "token.dep_ = 'ROOT'\n",
      "\n",
      "TOKEN: piano\n",
      "=====\n",
      "token.tag_ = 'NN'\n",
      "token.head.text = 'learning'\n",
      "token.dep_ = 'dobj'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"d1ee28ef01274ad58455a84dddacdeb2-0\" class=\"displacy\" width=\"750\" height=\"312.0\" direction=\"ltr\" style=\"max-width: none; height: 312.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Gus</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">is</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">AUX</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">learning</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">piano</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-d1ee28ef01274ad58455a84dddacdeb2-0-0\" stroke-width=\"2px\" d=\"M70,177.0 C70,2.0 400.0,2.0 400.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-d1ee28ef01274ad58455a84dddacdeb2-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,179.0 L62,167.0 78,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-d1ee28ef01274ad58455a84dddacdeb2-0-1\" stroke-width=\"2px\" d=\"M245,177.0 C245,89.5 395.0,89.5 395.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-d1ee28ef01274ad58455a84dddacdeb2-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M245,179.0 L237,167.0 253,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-d1ee28ef01274ad58455a84dddacdeb2-0-2\" stroke-width=\"2px\" d=\"M420,177.0 C420,89.5 570.0,89.5 570.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-d1ee28ef01274ad58455a84dddacdeb2-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M570.0,179.0 L578.0,167.0 562.0,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Extracting the dependency graph of a sentence to represent its grammatical structure\n",
    "# Defines relationships between headwords and their dependents\n",
    "# The head of a sentence has no dependency and is called the root of a sentence\n",
    "\n",
    "piano_text = \"Gus is learning piano\"\n",
    "\n",
    "piano_doc = nlp(piano_text)\n",
    "\n",
    "for token in piano_doc:\n",
    "    print(\n",
    "        f\"\"\"\n",
    "TOKEN: {token.text}\n",
    "=====\n",
    "{token.tag_ = }\n",
    "{token.head.text = }\n",
    "{token.dep_ = }\"\"\"\n",
    "    )\n",
    "# Prints the tag, the word, and its dependency with respect to a sentence\n",
    "\n",
    "displacy.render(piano_doc, style=\"dep\", jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206620cf-e549-42e2-98fe-339e314c808a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Trees and subtree navigation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036f152e-60e1-4480-b69b-c5c356c53aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependency graphs have all the properties of a tree and can be traversed like one\n",
    "\n",
    "one_line_about_text = (\n",
    "    \"Gus Proto is a Python developer\"\n",
    "    \" currently working for a London-based Fintech company\"\n",
    ")\n",
    "\n",
    "one_line_about_doc = nlp(one_line_about_text)\n",
    "\n",
    "# Extract children of `developer`\n",
    "print([token.text for token in one_line_about_doc[5].children])\n",
    "\n",
    "# Extract previous neighboring node of `developer`\n",
    "print (one_line_about_doc[5].nbor(-1))\n",
    "\n",
    "\n",
    "# Extract next neighboring node of `developer`\n",
    "print (one_line_about_doc[5].nbor(1))\n",
    "\n",
    "\n",
    "# Extract all tokens on the left of `developer`\n",
    "print([token.text for token in one_line_about_doc[5].lefts])\n",
    "\n",
    "\n",
    "# Extract tokens on the right of `developer`\n",
    "print([token.text for token in one_line_about_doc[5].rights])\n",
    "\n",
    "\n",
    "# Print subtree of `developer`\n",
    "print(\"This is the subtree of 'developer':\")\n",
    "print (list(one_line_about_doc[5].subtree))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f94885-63e7-45d2-9483-31d2ce4b39ca",
   "metadata": {},
   "source": [
    "### Shallow parsing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "ec9b4467-ad0f-4974-9675-52cc8caebf1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a developer conference\n",
      "21 July\n",
      "London\n"
     ]
    }
   ],
   "source": [
    "# Extracting phrases from unstructured text\n",
    "# Involves chunking groups of adjacent tokens into phrases on the basis of POS tags\n",
    "# Well-known chunks include noun phrases, verb phrases, and preposiitonal phrases\n",
    "\n",
    "# Noun phrase detection - has a noun at its head and can include adjectives, ordinals and determiners\n",
    "conference_text = (\n",
    "    \"There is a developer conference happening on 21 July 2019 in London.\"\n",
    ")\n",
    "conference_doc = nlp(conference_text)\n",
    "\n",
    "# Extract Noun Phrases\n",
    "for chunk in conference_doc.noun_chunks:\n",
    "    print (chunk)\n",
    "\n",
    "\n",
    "# Verb phrase detection - syntactic unit composed of atleast one verb\n",
    "# Must use python -m pip install textacy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25fcba24-f483-4bf6-b41d-03feabce2bd2",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'textacy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtextacy\u001b[39;00m\n\u001b[1;32m      3\u001b[0m about_talk_text \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe talk will introduce reader about use\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m cases of Natural Language Processing in\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Fintech, making use of\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m interesting examples along the way.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      8\u001b[0m )\n\u001b[1;32m     10\u001b[0m patterns \u001b[38;5;241m=\u001b[39m [{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPOS\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAUX\u001b[39m\u001b[38;5;124m\"\u001b[39m}, {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPOS\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVERB\u001b[39m\u001b[38;5;124m\"\u001b[39m}]\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'textacy'"
     ]
    }
   ],
   "source": [
    "import textacy\n",
    "\n",
    "about_talk_text = (\n",
    "    \"The talk will introduce reader about use\"\n",
    "    \" cases of Natural Language Processing in\"\n",
    "    \" Fintech, making use of\"\n",
    "    \" interesting examples along the way.\"\n",
    ")\n",
    "\n",
    "patterns = [{\"POS\": \"AUX\"}, {\"POS\": \"VERB\"}]\n",
    "about_talk_doc = textacy.make_spacy_doc(\n",
    "    about_talk_text, lang=\"en_core_web_sm\"\n",
    ")\n",
    "verb_phrases = textacy.extract.token_matches(\n",
    "    about_talk_doc, patterns=patterns\n",
    ")\n",
    "\n",
    "# Print all verb phrases\n",
    "for chunk in verb_phrases:\n",
    "    print(chunk.text)\n",
    "\n",
    "\n",
    "\n",
    "# Extract noun phrase to explain what nouns are involved\n",
    "for chunk in about_talk_doc.noun_chunks:\n",
    "    print (chunk)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "3a4044bd-5377-425c-aaa1-636ab4497f67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ent.text = 'Great Piano Academy'\n",
      "ent.start_char = 0\n",
      "ent.end_char = 19\n",
      "ent.label_ = 'ORG'\n",
      "spacy.explain('ORG') = Companies, agencies, institutions, etc.\n",
      "\n",
      "ent.text = 'Mayfair'\n",
      "ent.start_char = 35\n",
      "ent.end_char = 42\n",
      "ent.label_ = 'GPE'\n",
      "spacy.explain('GPE') = Countries, cities, states\n",
      "\n",
      "ent.text = 'the City of London'\n",
      "ent.start_char = 46\n",
      "ent.end_char = 64\n",
      "ent.label_ = 'GPE'\n",
      "spacy.explain('GPE') = Countries, cities, states\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"09cefec042e349b89e8e1682976b4cb7-0\" class=\"displacy\" width=\"3200\" height=\"487.0\" direction=\"ltr\" style=\"max-width: none; height: 487.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Great</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">Piano</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">Academy</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">is</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">AUX</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">situated</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">in</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">Mayfair</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">or</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\">CCONJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1450\">the</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1450\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1625\">City</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1625\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1800\">of</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1800\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1975\">London</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1975\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2150\">and</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2150\">CCONJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2325\">has</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2325\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2500\">world-</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2500\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2675\">class</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2675\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2850\">piano</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2850\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3025\">instructors.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3025\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-09cefec042e349b89e8e1682976b4cb7-0-0\" stroke-width=\"2px\" d=\"M70,352.0 C70,177.0 390.0,177.0 390.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-09cefec042e349b89e8e1682976b4cb7-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,354.0 L62,342.0 78,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-09cefec042e349b89e8e1682976b4cb7-0-1\" stroke-width=\"2px\" d=\"M245,352.0 C245,264.5 385.0,264.5 385.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-09cefec042e349b89e8e1682976b4cb7-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M245,354.0 L237,342.0 253,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-09cefec042e349b89e8e1682976b4cb7-0-2\" stroke-width=\"2px\" d=\"M420,352.0 C420,177.0 740.0,177.0 740.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-09cefec042e349b89e8e1682976b4cb7-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubjpass</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M420,354.0 L412,342.0 428,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-09cefec042e349b89e8e1682976b4cb7-0-3\" stroke-width=\"2px\" d=\"M595,352.0 C595,264.5 735.0,264.5 735.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-09cefec042e349b89e8e1682976b4cb7-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">auxpass</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M595,354.0 L587,342.0 603,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-09cefec042e349b89e8e1682976b4cb7-0-4\" stroke-width=\"2px\" d=\"M770,352.0 C770,264.5 910.0,264.5 910.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-09cefec042e349b89e8e1682976b4cb7-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M910.0,354.0 L918.0,342.0 902.0,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-09cefec042e349b89e8e1682976b4cb7-0-5\" stroke-width=\"2px\" d=\"M945,352.0 C945,264.5 1085.0,264.5 1085.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-09cefec042e349b89e8e1682976b4cb7-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1085.0,354.0 L1093.0,342.0 1077.0,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-09cefec042e349b89e8e1682976b4cb7-0-6\" stroke-width=\"2px\" d=\"M1120,352.0 C1120,264.5 1260.0,264.5 1260.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-09cefec042e349b89e8e1682976b4cb7-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">cc</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1260.0,354.0 L1268.0,342.0 1252.0,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-09cefec042e349b89e8e1682976b4cb7-0-7\" stroke-width=\"2px\" d=\"M1470,352.0 C1470,264.5 1610.0,264.5 1610.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-09cefec042e349b89e8e1682976b4cb7-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1470,354.0 L1462,342.0 1478,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-09cefec042e349b89e8e1682976b4cb7-0-8\" stroke-width=\"2px\" d=\"M1120,352.0 C1120,177.0 1615.0,177.0 1615.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-09cefec042e349b89e8e1682976b4cb7-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">conj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1615.0,354.0 L1623.0,342.0 1607.0,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-09cefec042e349b89e8e1682976b4cb7-0-9\" stroke-width=\"2px\" d=\"M1645,352.0 C1645,264.5 1785.0,264.5 1785.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-09cefec042e349b89e8e1682976b4cb7-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1785.0,354.0 L1793.0,342.0 1777.0,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-09cefec042e349b89e8e1682976b4cb7-0-10\" stroke-width=\"2px\" d=\"M1820,352.0 C1820,264.5 1960.0,264.5 1960.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-09cefec042e349b89e8e1682976b4cb7-0-10\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1960.0,354.0 L1968.0,342.0 1952.0,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-09cefec042e349b89e8e1682976b4cb7-0-11\" stroke-width=\"2px\" d=\"M770,352.0 C770,89.5 2145.0,89.5 2145.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-09cefec042e349b89e8e1682976b4cb7-0-11\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">cc</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M2145.0,354.0 L2153.0,342.0 2137.0,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-09cefec042e349b89e8e1682976b4cb7-0-12\" stroke-width=\"2px\" d=\"M770,352.0 C770,2.0 2325.0,2.0 2325.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-09cefec042e349b89e8e1682976b4cb7-0-12\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">conj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M2325.0,354.0 L2333.0,342.0 2317.0,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-09cefec042e349b89e8e1682976b4cb7-0-13\" stroke-width=\"2px\" d=\"M2520,352.0 C2520,264.5 2660.0,264.5 2660.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-09cefec042e349b89e8e1682976b4cb7-0-13\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M2520,354.0 L2512,342.0 2528,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-09cefec042e349b89e8e1682976b4cb7-0-14\" stroke-width=\"2px\" d=\"M2695,352.0 C2695,177.0 3015.0,177.0 3015.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-09cefec042e349b89e8e1682976b4cb7-0-14\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M2695,354.0 L2687,342.0 2703,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-09cefec042e349b89e8e1682976b4cb7-0-15\" stroke-width=\"2px\" d=\"M2870,352.0 C2870,264.5 3010.0,264.5 3010.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-09cefec042e349b89e8e1682976b4cb7-0-15\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M2870,354.0 L2862,342.0 2878,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-09cefec042e349b89e8e1682976b4cb7-0-16\" stroke-width=\"2px\" d=\"M2345,352.0 C2345,89.5 3020.0,89.5 3020.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-09cefec042e349b89e8e1682976b4cb7-0-16\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M3020.0,354.0 L3028.0,342.0 3012.0,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Named entity recognition\n",
    "# Process of locating named entities to classify them in categories\n",
    "# Populate tags for a set of documents, in order to improve the keyword search.\n",
    "\n",
    "piano_class_text = (\n",
    "    \"Great Piano Academy is situated\"\n",
    "    \" in Mayfair or the City of London and has\"\n",
    "    \" world-class piano instructors.\"\n",
    ")\n",
    "\n",
    "piano_class_doc = nlp(piano_class_text)\n",
    "\n",
    "for ent in piano_class_doc.ents:\n",
    "    # .text gives the actual text\n",
    "    # .start_char denotes the starting index\n",
    "    # .end_char denotes the ending index\n",
    "    # .label gives the label of the entity\n",
    "    print(\n",
    "        f\"\"\"\n",
    "{ent.text = }\n",
    "{ent.start_char = }\n",
    "{ent.end_char = }\n",
    "{ent.label_ = }\n",
    "spacy.explain('{ent.label_}') = {spacy.explain(ent.label_)}\"\"\"\n",
    ")\n",
    "\n",
    "displacy.render(piano_class_doc, style=\"dep\", jupyter=True)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "c7aca130-3299-4c72-988a-d9bad61de26c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out of 5 people surveyed, [REDACTED] , [REDACTED] and [REDACTED] like apples. [REDACTED] and [REDACTED] like oranges.\n"
     ]
    }
   ],
   "source": [
    "# Example in removing names from a survey_text\n",
    "\n",
    "survey_text = (\n",
    "    \"Out of 5 people surveyed, James Robert,\"\n",
    "    \" Julie Fuller and Benjamin Brooks like\"\n",
    "    \" apples. Kelly Cox and Matthew Evans\"\n",
    "    \" like oranges.\"\n",
    ")\n",
    "\n",
    "\n",
    "def replace_person_names(token):\n",
    "    # IOB code of the name - inside outside beginning tagging\n",
    "    if token.ent_iob != 0 and token.ent_type_ == \"PERSON\":\n",
    "        return \"[REDACTED] \"\n",
    "    return token.text_with_ws\n",
    "\n",
    "\n",
    "def redact_names(nlp_doc):\n",
    "    with nlp_doc.retokenize() as retokenizer:\n",
    "        for ent in nlp_doc.ents:\n",
    "            retokenizer.merge(ent)\n",
    "    tokens = map(replace_person_names, nlp_doc)\n",
    "    return \"\".join(tokens)\n",
    "\n",
    "\n",
    "survey_doc = nlp(survey_text)\n",
    "print(redact_names(survey_doc))\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
