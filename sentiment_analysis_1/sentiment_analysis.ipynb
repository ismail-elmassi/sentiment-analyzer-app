{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8779df-3885-4611-913f-8fbbf34e0752",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://realpython.com/sentiment-analysis-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "351dca9a-0bd0-4418-b38b-80d0a20665cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in /Users/kenny/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (3.7.4)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /Users/kenny/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /Users/kenny/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/kenny/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from spacy) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/kenny/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from spacy) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/kenny/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from spacy) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /Users/kenny/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from spacy) (8.2.3)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /Users/kenny/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from spacy) (1.1.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /Users/kenny/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from spacy) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /Users/kenny/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /Users/kenny/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from spacy) (0.3.4)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /Users/kenny/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from spacy) (0.9.4)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /Users/kenny/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from spacy) (6.4.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/kenny/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from spacy) (4.66.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/kenny/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from spacy) (2.31.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /Users/kenny/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from spacy) (2.7.1)\n",
      "Requirement already satisfied: jinja2 in /Users/kenny/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from spacy) (3.1.3)\n",
      "Requirement already satisfied: setuptools in /Users/kenny/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from spacy) (69.1.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/kenny/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from spacy) (23.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /Users/kenny/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from spacy) (3.4.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /Users/kenny/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from spacy) (1.26.4)\n",
      "Requirement already satisfied: language-data>=1.2 in /Users/kenny/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/kenny/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.2 in /Users/kenny/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.18.2)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /Users/kenny/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.10.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/kenny/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/kenny/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/kenny/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/kenny/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.2.2)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /Users/kenny/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /Users/kenny/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /Users/kenny/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from typer<0.10.0,>=0.3.0->spacy) (8.1.7)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /Users/kenny/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from weasel<0.4.0,>=0.1.0->spacy) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/kenny/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from jinja2->spacy) (2.1.5)\n",
      "Requirement already satisfied: marisa-trie>=0.7.7 in /Users/kenny/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.1.0)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "2285f1a6-81e3-4445-9852-58032f536bef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.7.1\n",
      "  Using cached https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n",
      "Requirement already satisfied: spacy<3.8.0,>=3.7.2 in /Users/kenny/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from en-core-web-sm==3.7.1) (3.7.4)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /Users/kenny/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /Users/kenny/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/kenny/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/kenny/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/kenny/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /Users/kenny/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.3)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /Users/kenny/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /Users/kenny/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /Users/kenny/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /Users/kenny/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.3.4)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /Users/kenny/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.9.4)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /Users/kenny/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (6.4.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/kenny/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.66.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/kenny/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.31.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /Users/kenny/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.7.1)\n",
      "Requirement already satisfied: jinja2 in /Users/kenny/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.3)\n",
      "Requirement already satisfied: setuptools in /Users/kenny/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (69.1.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/kenny/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (23.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /Users/kenny/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.4.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /Users/kenny/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.26.4)\n",
      "Requirement already satisfied: language-data>=1.2 in /Users/kenny/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/kenny/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.2 in /Users/kenny/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.18.2)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /Users/kenny/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.10.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/kenny/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/kenny/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/kenny/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/kenny/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2024.2.2)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /Users/kenny/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /Users/kenny/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /Users/kenny/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.1.7)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /Users/kenny/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/kenny/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.1.5)\n",
      "Requirement already satisfied: marisa-trie>=0.7.7 in /Users/kenny/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.0)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!python3 -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "08385d50-8fd0-4016-9933-5eb80e5f69fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<spacy.lang.en.English object at 0x137c35e80>\n",
      "\n",
      "Dave watched as the forest burned up on the hill,\n",
      "only a few miles from his house. The car had\n",
      "been hastily packed and Marta was inside trying to round\n",
      "up the last of the pets. \"Where could she be?\" he wondered\n",
      "as he continued to wait for Marta to appear with the pets.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "text = \"\"\"\n",
    "Dave watched as the forest burned up on the hill,\n",
    "only a few miles from his house. The car had\n",
    "been hastily packed and Marta was inside trying to round\n",
    "up the last of the pets. \"Where could she be?\" he wondered\n",
    "as he continued to wait for Marta to appear with the pets.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# NLP constructor\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "print(nlp)\n",
    "\n",
    "doc = nlp(text)\n",
    "\n",
    "print(doc)\n",
    "\n",
    "token_list = [token for token in doc]\n",
    "# print(token_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "95b68804-d43a-4a27-a1dd-88b6429a0a02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      ", Dave, watched, forest, burned, hill, ,, \n",
      ", miles, house, ., car, \n",
      ", hastily, packed, Marta, inside, trying, round, \n",
      ", pets, ., \", ?, \", wondered, \n",
      ", continued, wait, Marta, appear, pets, ., \n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# Remove stop words\n",
    "filtered_tokens = [token for token in doc if not token.is_stop]\n",
    "print(filtered_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d451e4ac-8c45-408a-9c30-fb9e8e7456b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Token: \\n, lemma: \\n',\n",
       " 'Token: Dave, lemma: Dave',\n",
       " 'Token: watched, lemma: watch',\n",
       " 'Token: forest, lemma: forest',\n",
       " 'Token: burned, lemma: burn',\n",
       " 'Token: hill, lemma: hill',\n",
       " 'Token: ,, lemma: ,',\n",
       " 'Token: \\n, lemma: \\n',\n",
       " 'Token: miles, lemma: mile',\n",
       " 'Token: house, lemma: house',\n",
       " 'Token: ., lemma: .',\n",
       " 'Token: car, lemma: car',\n",
       " 'Token: \\n, lemma: \\n',\n",
       " 'Token: hastily, lemma: hastily',\n",
       " 'Token: packed, lemma: pack',\n",
       " 'Token: Marta, lemma: Marta',\n",
       " 'Token: inside, lemma: inside',\n",
       " 'Token: trying, lemma: try',\n",
       " 'Token: round, lemma: round',\n",
       " 'Token: \\n, lemma: \\n',\n",
       " 'Token: pets, lemma: pet',\n",
       " 'Token: ., lemma: .',\n",
       " 'Token: \", lemma: \"',\n",
       " 'Token: ?, lemma: ?',\n",
       " 'Token: \", lemma: \"',\n",
       " 'Token: wondered, lemma: wonder',\n",
       " 'Token: \\n, lemma: \\n',\n",
       " 'Token: continued, lemma: continue',\n",
       " 'Token: wait, lemma: wait',\n",
       " 'Token: Marta, lemma: Marta',\n",
       " 'Token: appear, lemma: appear',\n",
       " 'Token: pets, lemma: pet',\n",
       " 'Token: ., lemma: .',\n",
       " 'Token: \\n, lemma: \\n']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalize the words\n",
    "# Stemming and lemmatization (only lemmatization is provided by spaCy)\n",
    "lemmas = [\n",
    "    f\"Token: {token}, lemma: {token.lemma_}\"\n",
    "    for token in filtered_tokens\n",
    "]\n",
    "lemmas\n",
    "\n",
    "# Note the underscore returns the readable version of the lemma here\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "541de5d0-f7c6-45d3-81b0-f17dbf2cc75b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.0732636 , -1.5893133 , -0.7485422 ,  0.80338854,  0.199772  ,\n",
       "        0.00840409,  1.5419112 ,  0.78789294, -0.10507858, -0.08379468,\n",
       "        1.6370184 ,  0.9981552 , -0.27276078, -0.90784246, -1.248598  ,\n",
       "       -0.5253062 ,  0.36606142,  0.3220521 ,  0.26947665, -0.6838576 ,\n",
       "       -1.3466266 ,  0.01122165, -0.24088567, -0.48466757, -0.33174923,\n",
       "       -0.05325297,  1.8773435 ,  0.5649502 , -0.9605744 ,  0.78610945,\n",
       "       -0.44939822, -1.4648836 , -0.38066614,  1.0480766 , -0.83412176,\n",
       "       -0.2217491 , -0.854434  ,  0.35594553, -0.11274697,  1.2787786 ,\n",
       "       -0.8223142 ,  0.18473107, -0.08983883,  0.6325264 , -1.1029457 ,\n",
       "        0.37194866,  0.11167954,  1.529881  ,  0.73127055, -0.01238401,\n",
       "       -0.38741043,  0.24374214,  0.66934144, -0.5147386 , -0.05107623,\n",
       "       -0.68364084,  1.2553529 , -0.4258138 ,  0.8257121 , -0.40289953,\n",
       "       -1.0714421 ,  0.8215431 ,  0.1035445 , -0.5627636 ,  0.34108096,\n",
       "       -0.46954772, -0.6444609 , -0.4248718 , -0.74732184, -0.93381315,\n",
       "        0.54961896,  0.95218015,  1.8080062 ,  0.77191067, -0.06320465,\n",
       "       -1.1639178 , -0.37379634, -2.0506837 , -0.2422083 , -0.6951567 ,\n",
       "       -0.68725175,  0.7614975 , -0.8780632 ,  0.6869065 ,  1.4673206 ,\n",
       "       -0.3449759 ,  0.805764  , -0.30646116, -0.6471175 ,  0.15497795,\n",
       "       -0.39263946, -0.12381144,  2.092909  ,  0.07248274,  1.3887855 ,\n",
       "        1.6653665 ], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vectorize the text\n",
    "filtered_tokens[1].vector\n",
    "# Dense arrays have defined values in every space of the array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3bc8964f-877a-4947-9376-fe0edd292197",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load the data\n",
    "# 80% training data, 20% test data\n",
    "\n",
    "\n",
    "def load_training_data(\n",
    "    # Data directory\n",
    "    data_directory: str = \"aclImdb/train\",\n",
    "    split: float = 0.8,\n",
    "    limit: int = 0\n",
    ") -> tuple:\n",
    "    # Create a list to store the list of tuples\n",
    "    reviews = []\n",
    "    # label will give the folder name in each of the two directories\n",
    "    for label in [\"pos\", \"neg\"]:\n",
    "        # Create the full directory path to the pos and neg folders\n",
    "        labeled_directory = f\"{data_directory}/{label}\"\n",
    "        # Create the full directory to each of the text files in the pos and negative folders\n",
    "        for review in os.listdir(labeled_directory):\n",
    "            if review.endswith(\".txt\"):\n",
    "                with open(f\"{labeled_directory}/{review}\") as f:\n",
    "                    # Clean the data\n",
    "                    text = f.read()\n",
    "                    text = text.replace(\"<br />\", \"\\n\\n\")\n",
    "                    if text.strip():\n",
    "                        # Create a dictionary for the label of the .txt file (cats stands for category)\n",
    "                        # The format must be a dictionary for spaCy to work\n",
    "                        spacy_label = {\"cats\": {\"pos\": \"pos\" == label, \"neg\": \"neg\" == label}}\n",
    "                        # Add the tuple back to the reviews list\n",
    "                        reviews.append((text, spacy_label))\n",
    "    random.shuffle(reviews)\n",
    "    if limit:\n",
    "        reviews = reviews[:limit]\n",
    "    split = int(len(reviews) * split)\n",
    "    # First is the training set, second is the validation/test set\n",
    "    return reviews[:split], reviews[split:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b536ea28-75fd-41fd-94f7-fc010cd929c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Train the classifier\n",
    "# After loading data, we need to add our cat labels to textcat\n",
    "import os\n",
    "import random\n",
    "import spacy\n",
    "\n",
    "# 3. Build the training loop\n",
    "# Train only the textcat component\n",
    "\n",
    "from spacy.util import minibatch, compounding\n",
    "\n",
    "\n",
    "def train_model(training_data: list, test_data: list, iterations: int = 20) -> None:\n",
    "    # Data pipeline\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    # Check if textcat is available\n",
    "    \n",
    "    if \"textcat\" not in nlp.pipe_names:\n",
    "        # textcat = nlp.add_pipe(\"textcat\", name = \"textcat\")\n",
    "        # Add pipe to the end\n",
    "        textcat = nlp.add_pipe(\"textcat\", name = \"textcat\", last = True)\n",
    "\n",
    "    else:\n",
    "        textcat = nlp.get_pipe(\"textcat\")\n",
    "    textcat.add_label(\"pos\")\n",
    "    textcat.add_label(\"neg\")\n",
    "\n",
    "    # Train only textcat\n",
    "    training_excluded_pipes = [\n",
    "        pipe for pipe in nlp.pipe_names if pipe != \"textcat\"\n",
    "    ]\n",
    "\n",
    "    # Disable pipelines other than textcat\n",
    "    with nlp.disable_pipes(training_excluded_pipes):\n",
    "        # Call the optimizer function\n",
    "        # optimizer = nlp.begin_training()\n",
    "        optimizer = nlp.create_optimizer()\n",
    "        # Training loop\n",
    "        print(\"Start of training:\")\n",
    "        print(\"Loss\\tPrecision\\tRecall\\tF-score\")\n",
    "        # Creates a generator to create batch sizes\n",
    "        batch_sizes = compounding(4.0, 32.0, 1.001)  # A generator that yields infinite series of input numbers\n",
    "        \n",
    "        for i in range(iterations):\n",
    "                loss = {}\n",
    "                # At each iteration, shuffle the data, get new batches\n",
    "                random.shuffle(training_data)\n",
    "                batches = minibatch(training_data, size=batch_sizes)\n",
    "                # Run the SGD on each batch and update the model weights and biases\n",
    "                for batch in batches:\n",
    "                    text, labels = zip(*batch)\n",
    "                    # Update the loss dictionary\n",
    "                    # The drop hyperparamters tells the model what proportion of training data in the batch to skip over\n",
    "                    nlp.update(text, labels, drop=0.2, sgd=optimizer, losses=loss)\n",
    "\n",
    "                \n",
    "                with textcat.model.use_params(optimizer.averages):\n",
    "                    evaluation_results = evaluate_model(\n",
    "                        tokenizer=nlp.tokenizer,\n",
    "                        textcat=textcat,\n",
    "                        test_data=test_data\n",
    "                    )\n",
    "                    print(\n",
    "                        f\"{loss['textcat']}\\t{evaluation_results['precision']}\"\n",
    "                        f\"\\t{evaluation_results['recall']}\"\n",
    "                        f\"\\t{evaluation_results['f-score']}\"\n",
    "                    )\n",
    "\n",
    "    with nlp.use_params(optimizer.averages):\n",
    "        nlp.to_disk(\"model_artifacts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5dfbb329-ab21-47dd-876e-2dc622d89c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the progress of training\n",
    "# True positive, true negative, false positive, false negative\n",
    "# Calculate the precision (# of successful classification vs # of incorrect)\n",
    "# Calculate the recall (# of sucessful classification / # of incorrect)\n",
    "# F-score - metric for evaluating effectiveness of a binary classification model\n",
    "\n",
    "def evaluate_model(tokenizer, textcat, test_data: list) -> dict:\n",
    "    reviews, labels = zip(*test_data)\n",
    "    reviews = (tokenizer(review) for review in reviews)\n",
    "    true_positives = 0\n",
    "    false_positives = 1e-8  # Set to a low number\n",
    "    true_negatives = 0\n",
    "    false_negatives = 1e-8\n",
    "    # \n",
    "    for i, review in enumerate(textcat.pipe(reviews)):\n",
    "        true_label = labels[i]\n",
    "        for predicted_label, score in review.cats.items():\n",
    "            # Every cats dictionary includes both labels. You can get all\n",
    "            # the info you need with just the pos label.\n",
    "            if (\n",
    "                predicted_label == \"neg\"\n",
    "            ):\n",
    "                continue\n",
    "            if score >= 0.5 and true_label[\"pos\"]:\n",
    "                true_positives += 1\n",
    "            elif score >= 0.5 and true_label[\"neg\"]:\n",
    "                false_positives += 1\n",
    "            elif score < 0.5 and true_label[\"neg\"]:\n",
    "                true_negatives += 1\n",
    "            elif score < 0.5 and true_label[\"pos\"]:\n",
    "                false_negatives += 1\n",
    "    precision = true_positives / (true_positives + false_positives)\n",
    "    recall = true_positives / (true_positives + false_negatives)\n",
    "\n",
    "    if precision + recall == 0:\n",
    "        f_score = 0\n",
    "    else:\n",
    "        f_score = 2 * (precision * recall) / (precision + recall)\n",
    "    return {\"precision\": precision, \"recall\": recall, \"f-score\": f_score}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fbb83a33-5801-4399-a2d4-d89a1e0fc853",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_REVIEW = \"\"\"\n",
    "Transcendently beautiful in moments outside the office, it seems almost\n",
    "sitcom-like in those scenes. When Toni Colette walks out and ponders\n",
    "life silently, it's gorgeous.<br /><br />The movie doesn't seem to decide\n",
    "whether it's slapstick, farce, magical realism, or drama, but the best of it\n",
    "doesn't matter. (The worst is sort of tedious - like Office Space with less humor.)\n",
    "\"\"\"\n",
    "\n",
    "def test_model(input_data: str = TEST_REVIEW):\n",
    "    #  Load saved trained model\n",
    "    loaded_model = spacy.load(\"model_artifacts\")\n",
    "    # Generate prediction\n",
    "    parsed_text = loaded_model(input_data)\n",
    "    # Determine prediction to return\n",
    "    if parsed_text.cats[\"pos\"] > parsed_text.cats[\"neg\"]:\n",
    "        prediction = \"Positive\"\n",
    "        score = parsed_text.cats[\"pos\"]\n",
    "    else:\n",
    "        prediction = \"Negative\"\n",
    "        score = parsed_text.cats[\"neg\"]\n",
    "    print(\n",
    "        f\"Review text: {input_data}\\nPredicted sentiment: {prediction}\"\n",
    "        f\"\\tScore: {score}\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "2c1c4548-fbd6-424a-a497-9a19a60932e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start of training:\n",
      "Loss\tPrecision\tRecall\tF-score\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "[E989] `nlp.update()` was called with two positional arguments. This may be due to a backwards-incompatible change to the format of the training data in spaCy 3.0 onwards. The 'update' function should now be called with a batch of Example objects, instead of `(text, annotation)` tuples. ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[80], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m spacy\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124men_core_web_sm\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m train, test \u001b[38;5;241m=\u001b[39m load_training_data(limit\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2500\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTesting model\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m test_model()\n",
      "Cell \u001b[0;32mIn[79], line 54\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(training_data, test_data, iterations)\u001b[0m\n\u001b[1;32m     51\u001b[0m     text, labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch)\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;66;03m# Update the loss dictionary\u001b[39;00m\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;66;03m# The drop hyperparamters tells the model what proportion of training data in the batch to skip over\u001b[39;00m\n\u001b[0;32m---> 54\u001b[0m     \u001b[43mnlp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdrop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msgd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlosses\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m textcat\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39muse_params(optimizer\u001b[38;5;241m.\u001b[39maverages):\n\u001b[1;32m     58\u001b[0m     evaluation_results \u001b[38;5;241m=\u001b[39m evaluate_model(\n\u001b[1;32m     59\u001b[0m         tokenizer\u001b[38;5;241m=\u001b[39mnlp\u001b[38;5;241m.\u001b[39mtokenizer,\n\u001b[1;32m     60\u001b[0m         textcat\u001b[38;5;241m=\u001b[39mtextcat,\n\u001b[1;32m     61\u001b[0m         test_data\u001b[38;5;241m=\u001b[39mtest_data\n\u001b[1;32m     62\u001b[0m     )\n",
      "File \u001b[0;32m~/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages/spacy/language.py:1171\u001b[0m, in \u001b[0;36mLanguage.update\u001b[0;34m(self, examples, _, drop, sgd, losses, component_cfg, exclude, annotates)\u001b[0m\n\u001b[1;32m   1153\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Update the models in the pipeline.\u001b[39;00m\n\u001b[1;32m   1154\u001b[0m \n\u001b[1;32m   1155\u001b[0m \u001b[38;5;124;03mexamples (Iterable[Example]): A batch of examples\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1168\u001b[0m \u001b[38;5;124;03mDOCS: https://spacy.io/api/language#update\u001b[39;00m\n\u001b[1;32m   1169\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1170\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _ \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1171\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(Errors\u001b[38;5;241m.\u001b[39mE989)\n\u001b[1;32m   1172\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m losses \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1173\u001b[0m     losses \u001b[38;5;241m=\u001b[39m {}\n",
      "\u001b[0;31mValueError\u001b[0m: [E989] `nlp.update()` was called with two positional arguments. This may be due to a backwards-incompatible change to the format of the training data in spaCy 3.0 onwards. The 'update' function should now be called with a batch of Example objects, instead of `(text, annotation)` tuples. "
     ]
    }
   ],
   "source": [
    "# Run train_model()\n",
    "spacy.load('en_core_web_sm')\n",
    "train, test = load_training_data(limit=2500)\n",
    "train_model(train, test)\n",
    "print(\"Testing model\")\n",
    "test_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "cd01b8d6-5cd9-4446-8042-74be768ff645",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1936713450.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[81], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    For after bug fixes:\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "For after bug fixes:\n",
    "https://stackoverflow.com/questions/66675261/how-can-i-work-with-example-for-nlp-update-problem-with-spacy3-0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec39cd2c-36fa-4482-b65f-286f133f4b18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c627f09-fa02-4047-abdc-c669251670fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be71f6d4-f1c6-4796-b36a-b0949b706bfc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
